# üìç Waze User Churn Prediction

## üß† Project Overview

This project focuses on building predictive models to identify users likely to churn from the **Waze application**. By analyzing historical user behavior, the goal is to uncover key patterns that contribute to churn and deliver **data-driven recommendations** to enhance retention strategies.

This work demonstrates the application of **machine learning**, **feature engineering**, and **model interpretability** in solving a real-world business problem for a product-driven organization.

---

## üéØ Objectives

- üìâ **Predict Churn:** Develop machine learning models that forecast user attrition.
- üõ†Ô∏è **Feature Engineering:** Identify behavioral and usage patterns that act as leading indicators of churn.
- üß™ **Model Evaluation:** Validate models using multiple performance metrics to ensure reliability and business relevance.

---

## üì¶ Key Deliverables

- üìÑ **[One-Page Summary](link-to-summary)**  
  Concise report for business stakeholders, summarizing insights and strategic recommendations.

- üìì **[Code Notebook](link-to-notebook)**  
  A comprehensive Jupyter notebook covering data preprocessing, modeling pipeline, evaluation, and visualizations.

---

## üîÑ Project Lifecycle (PACE Framework)

### 1. üß≠ Plan
- Clearly defined churn prediction as a supervised classification task.
- Outlined workflow and established evaluation strategy (precision/recall-focused).

### 2. üîç Analyze
- Conducted **exploratory data analysis (EDA)** to discover usage trends and potential churn triggers.
- Identified significant churn correlates using distributions, correlation matrices, and segmentation analysis.

### 3. üß± Construct
- Built multiple models, starting with **Logistic Regression** for baseline performance.
- Advanced to **Decision Tree** and **Random Forest** classifiers.
- Conducted two rounds of modeling (pre and post-feature engineering) to quantify feature impact.

### 4. üìä Execute
- Assessed models using:
  - **Accuracy**
  - **Precision**
  - **Recall**
  - **F1-score**
- Focused on **Recall**, minimizing false negatives to ensure at-risk users are flagged effectively.
- Used **feature importance** and visualization to interpret and explain results.

---

## üß∞ Tech Stack

| Category          | Tools & Libraries |
|------------------|-------------------|
| Language          | Python            |
| IDE / Notebook    | Jupyter Notebook  |
| Libraries         | pandas, numpy, scikit-learn, matplotlib, seaborn |
| Modeling Techniques | Logistic Regression, Decision Tree, Random Forest |

---

## üìà Visual Analytics

Visuals were created to:
- Illustrate usage behavior over time
- Highlight key differences between retained and churned users
- Show feature importance and model diagnostics

---

## üìâ Model Performance Highlights

| Metric     | Value (Example) |
|------------|-----------------|
| Accuracy   | 0.814780        |
| Precision  | 0.442586        |
| Recall     | 0.173468        |
| F1-score   | 0.248972        |

## üß† Ethical Considerations

- ‚úÖ Maintained user **data privacy** and followed responsible data use practices
- ‚úÖ Avoided any demographic bias during model development
- ‚úÖ Positioned the model as a **decision support system** rather than a fully automated judgment tool

---

## üì¨ Contact

If you'd like to connect, collaborate, or discuss the project:

- ‚úâÔ∏è Email: [loviaeb@gmail.com](mailto:loviaeb@gmail.com)  
- üîó LinkedIn: [linkedin.com/in/lovia-edassery](https://www.linkedin.com/in/lovia-edassery)

---

> ‚≠ê _This project reflects my passion for using data to drive user-centric product decisions and showcases my technical, analytical, and ethical approach to machine learning._

